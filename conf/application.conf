# This is the main configuration file for the application.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
application.secret="@v`?6xe4JidF2tsu/WJ<l@=kR6t:3]_VgO]_B/KD6vAhU=iROa:Li^96]>_pc`Hb"

# The application languages
# ~~~~~
application.langs="en"

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
# application.global=Global

# Router 
# ~~~~~
# Define the Router object to use for this application.
# This router will be looked up first when the application is starting up,
# so make sure this is the entry point. 
# Furthermore, it's assumed your route file is named properly. 
# So for an application router like `conf/my.application.Router`,
# you may need to define a router file `my.application.routes`.
# Default to Routes in the root package (and `conf/routes`)
# application.router=my.application.Routes

# Database configuration
# ~~~~~ 
# You can declare as many datasources as you want.
# By convention, the default datasource is named `default`
#
db.default.driver=com.mysql.jdbc.Driver
db.default.url="jdbc:mysql://st1dg.prod.mediav.com:3306/hadoop"
db.default.user="hadoop"
db.default.password="RNymee2527#"


#
# You can expose this datasource via JNDI if needed (Useful for JPA)
# db.default.jndiName=DefaultDS

# Evolutions
# ~~~~~
# You can disable evolutions if needed
evolutionplugin=disabled
applyEvolutions.default=true

# Ebean configuration
# ~~~~~
# You can declare as many Ebean servers as you want.
# By convention, the default server is named `default`
#
ebean.default="models.*"

# Logger
# ~~~~~
# You can also configure logback (http://logback.qos.ch/), by providing a logger.xml file in the conf directory .

# Root logger:
logger.root=ERROR

# Logger used by the framework:
logger.play=INFO

# Logger provided to your application:
logger.application=DEBUG

hadoop.hdfs.namenode.http.address="nn1dg.prod.mediav.com:50070"
hadoop.mrv1.jobtracker.http.address="jt1dg.prod.mediav.com:50030"
hadoop.mapreduce.historyserver.http.address="jt2dg.prod.mediav.com:19888"
hadoop.yarn.resourcemanager.http.address="jt3dg.prod.mediav.com:8088"
hadoop.sparkonyarn.resourcemanager.http.address="jt5dg.prod.mediav.com:8088"
hadoop.hcatalog.webhcat.http.address="jt2dg.prod.mediav.com:50111"

sparksql.thriftserver.jdbc.url="jdbc:hive2://jt2dg.prod.mediav.com:10003"
sparksql.thriftserver.jdbc.user="hadoop"
sparksql.thriftserver.jdbc.password=""
sparksql.webui.url="http://jt2dg.prod.mediav.com:9099/proxy/application_1428573608660_0019/"


